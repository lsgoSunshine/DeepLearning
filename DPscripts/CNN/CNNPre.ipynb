{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[19., 25.],\n",
      "        [37., 43.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "'''二维卷积层'''\n",
    "'''该函数计算二维互相关运算'''\n",
    "def corr2d(X,K):\n",
    "    h,w=K.shape\n",
    "    #首先构造出运算过后的矩阵形状并用0填充\n",
    "    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "print(corr2d(X, K))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "'''图像中物体的边缘检测'''\n",
    "#构造一个简单的图像，中间为黑，两边为白\n",
    "X = torch.ones(6,8)\n",
    "X[:,2:6] = 0\n",
    "print(X)\n",
    "\n",
    "#构造一个简单的1*2的卷积核\n",
    "K = torch.tensor([[1,-1]])\n",
    "Y=corr2d(X,K)\n",
    "print(Y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Step 1, loss 208.282\n",
      "Step 2, loss 38.995\n",
      "Step 3, loss 22.112\n",
      "Step 4, loss 16.091\n",
      "Step 5, loss 12.042\n",
      "Step 6, loss 9.070\n",
      "Step 7, loss 6.860\n",
      "Step 8, loss 5.207\n",
      "Step 9, loss 3.964\n",
      "Step 10, loss 3.026\n",
      "Step 11, loss 2.315\n",
      "Step 12, loss 1.774\n",
      "Step 13, loss 1.362\n",
      "Step 14, loss 1.047\n",
      "Step 15, loss 0.806\n",
      "Step 16, loss 0.621\n",
      "Step 17, loss 0.479\n",
      "Step 18, loss 0.370\n",
      "Step 19, loss 0.285\n",
      "Step 20, loss 0.220\n",
      "tensor([[ 0.8889, -0.8741]]) tensor([-0.0083])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "'''卷积层的构造'''\n",
    "'''\n",
    "二维卷积层将输入和卷积和做互相关运算，并加上一个标量偏差来得到输出。\n",
    "卷积层模型参数包括卷积核和标量偏差\n",
    "最后得出的结果和上面的[1,-1]的卷积类似\n",
    "'''\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    #在构造函数中声明权重和偏差\n",
    "    def __init__(self,kernel_size):\n",
    "        super(Conv2D,self).__init__()\n",
    "        #随机初始化参数\n",
    "        self.weight=nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.randn(1))\n",
    "    def forward(self, x):\n",
    "        return corr2d(x,self.weight)+self.bias\n",
    "\n",
    "conv2d=Conv2D(kernel_size=(1,2))\n",
    "step=20\n",
    "lr=0.01\n",
    "for i in range(step):\n",
    "    Y_hat=conv2d(X)\n",
    "    l=((Y_hat-Y)**2).sum()\n",
    "    l.backward()\n",
    "    #梯度下降\n",
    "    conv2d.weight.data -=lr*conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr*conv2d.bias.grad\n",
    "    \n",
    "    #梯度清零\n",
    "    conv2d.weight.grad.zero_()\n",
    "    conv2d.bias.grad.zero_()\n",
    "    # if (i + 1) % 5 == 0:\n",
    "    print('Step %d, loss %.3f' % (i + 1, l.item()))\n",
    "print(conv2d.weight.data,conv2d.bias.data)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "'''这里展示了填充'''\n",
    "'''填充指的是再高和宽两侧填充元素（通常填充零元）'''\n",
    "#定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d,X):\n",
    "    #(1,1)代表批量大小和通道数，均为1,这里的view函数相当于给他们多增加俩维度\n",
    "    # print((1,1)+X.shape)\n",
    "    X=X.view((1,1)+X.shape)\n",
    "    # print(X)\n",
    "    Y=conv2d(X)\n",
    "    # print(Y)\n",
    "    #排除不关心的前两维：批量和通道，这里的view函数相当于只取i最后俩维度\n",
    "    return Y.view(Y.shape[2:])\n",
    "#创建一个高和宽都为3的卷积层，在高和宽两侧的填充数分别为1\n",
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,padding=1)\n",
    "X=torch.randn(4,4)\n",
    "Y=comp_conv2d(conv2d,X)\n",
    "# print(Y)\n",
    "\n",
    "#创建一个高和宽都为5和3的卷积层，在高和宽两侧的填充数分别为2，1\n",
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(5,3),padding=(2,1))\n",
    "X=torch.randn(4,4)\n",
    "Y=comp_conv2d(conv2d,X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 44
    }
   ],
   "source": [
    "'''这里展示步幅'''\n",
    "#在创建卷积层的时候添加stride参数就是步幅\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 56.,  72.],\n        [104., 120.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 45
    }
   ],
   "source": [
    "'''\n",
    "多输入通道，也就是上面的通道数那个维度数大于一的时候\n",
    "这时候就需要构造一个和通道数相等的卷积层然后用不同的通道对应不同的\n",
    "卷积运算，最后再相加\n",
    "'''\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 沿着X和K的第0维（通道维）分别计算再相加\n",
    "    res = corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res\n",
    "#验证一下，两个通道，两个卷积filter\n",
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "corr2d_multi_in(X, K)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 56.,  72.],\n         [104., 120.]],\n\n        [[ 76., 100.],\n         [148., 172.]],\n\n        [[ 96., 128.],\n         [192., 224.]]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 46
    }
   ],
   "source": [
    "'''\n",
    "多输出通道，\n",
    "'''\n",
    "def corr2d_multi_in_out(X, K):\n",
    "# 对K的第0维遍历，每次同输入X做互相关运算\n",
    "    #stack函数是用来连接tensor的\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])\n",
    "#这里需要构造一个输出通道*输入通道*高*宽的卷积层\n",
    "K = torch.stack([K, K + 1, K + 2])\n",
    "corr2d_multi_in_out(X, K)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[[0.8508, 0.4487, 0.9768],\n",
      "         [1.5421, 1.0475, 1.3409],\n",
      "         [1.0998, 0.8328, 1.4962]],\n",
      "\n",
      "        [[0.7753, 0.3442, 0.7942],\n",
      "         [1.0450, 1.0028, 0.8227],\n",
      "         [0.6375, 0.6872, 1.0389]]]) tensor([[[0.8508, 0.4487, 0.9768],\n",
      "         [1.5421, 1.0475, 1.3409],\n",
      "         [1.0998, 0.8328, 1.4962]],\n",
      "\n",
      "        [[0.7753, 0.3442, 0.7942],\n",
      "         [1.0450, 1.0028, 0.8227],\n",
      "         [0.6375, 0.6872, 1.0389]]])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "'''\n",
    "1*1卷积层\n",
    "调整网络层之间的通道数来控制模型复杂度\n",
    "'''\n",
    "'''\n",
    "可以想一想下，1*1卷积层和其他卷积比起来缺失了可以识别高和宽度维度上的相邻\n",
    "元素构成的模式的功能。\n",
    "所以它的运算主要发生在通道维度上，它可以起到增大或者减小通道维的值。\n",
    "比如：输入是3*3*3的图像，对它进行两个1*1的卷积运算得到的输出是3*3*2的图像矩阵。\n",
    "输出中的每个元素来自于输入中的高和宽上相同位置的元素再不同通道上按1*1给的卷积进行按权累加\n",
    "'''\n",
    "def corr2d_multi_in_out_1x1(X,K):\n",
    "    #通道数，高，宽\n",
    "    c_i, h,w=X.shape\n",
    "    # 1*1卷积通道数\n",
    "    c_o=K.shape[0]\n",
    "    X = X.view(c_i,h*w)\n",
    "    K=K.view(c_o,c_i)\n",
    "    Y=torch.mm(K,X)\n",
    "    return Y.view(c_o,h,w)\n",
    "#torch.randn和torch.rand一个是标准正态分布，一个是均匀分布\n",
    "X=torch.rand(3,3,3)\n",
    "K=torch.rand(2,3,1,1)\n",
    "Y1=corr2d_multi_in_out_1x1(X,K)\n",
    "Y2=corr2d_multi_in_out(X,K)\n",
    "print(Y1,Y2)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}